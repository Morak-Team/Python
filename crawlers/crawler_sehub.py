# ğŸ“Œ ì„œìš¸íŠ¹ë³„ì‹œ ì‚¬íšŒì ê²½ì œì§€ì›ì„¼í„° í¬ë¡¤ëŸ¬

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time

def run_sehub_crawling():
    driver = webdriver.Chrome()
    driver.get("https://sehub.net/archives/category/alarm/opencat")
    wait = WebDriverWait(driver, 10)
    results = []

    try:
        wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, "tbody tr")))
        rows = driver.find_elements(By.CSS_SELECTOR, "tbody tr")

        # âœ… inform ì œì™¸ + td.titleì— aíƒœê·¸ê°€ ìˆëŠ” ê²ƒë§Œ í•„í„°ë§
        normal_rows = [
            row for row in rows
            if "inform" not in row.get_attribute("class") and row.find_elements(By.CSS_SELECTOR, "td.title a")
        ]

        print(f"ğŸš¨ ì´ {len(normal_rows)}ê±´ ë°œê²¬ (inform ë° ë§í¬ ì—†ëŠ” í•­ëª© ì œì™¸)")

        for idx, row in enumerate(normal_rows[:10]):  # ìµœëŒ€ 10ê°œ
            try:
                # ë§í¬, ì œëª© ì¶”ì¶œ
                title_element = row.find_element(By.CSS_SELECTOR, "td.title a")
                title_text = title_element.text.strip()
                detail_link = title_element.get_attribute("href")

                # ì‘ì„±ì¼ ì¶”ì¶œ
                written_element = row.find_element(By.CSS_SELECTOR, "td.written")
                written_date = written_element.text.strip()

                # ìƒì„¸í˜ì´ì§€ ìƒˆ íƒ­ ì—´ê¸°
                driver.execute_script("window.open(arguments[0]);", detail_link)
                driver.switch_to.window(driver.window_handles[-1])

                wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.singleTitle h2")))
                time.sleep(0.5)

                # âœ… ìƒì„¸í˜ì´ì§€ ë°ì´í„° ì¶”ì¶œ
                try:
                    title_detail = driver.find_element(By.CSS_SELECTOR, "div.th12 h2").text.strip()
                except:
                    title_detail = title_text  # fallback

                try:
                    agency_info = driver.find_element(By.XPATH, '//li[contains(text(), "ì£¼ìµœ/ì£¼ê´€")]').text
                    agency = agency_info.split("ì£¼ìµœ/ì£¼ê´€ :")[-1].strip()
                except:
                    agency = "ìƒì„¸ ë§í¬ ì°¸ê³ "

                start_date = written_date if written_date else "ìƒì„¸ ë§í¬ ì°¸ê³ "
                end_date = "ìƒì„¸ ë§í¬ ì°¸ê³ "
                announcement_type = "ì‚¬íšŒì ê²½ì œ ê³µì§€"
                category = "ì‚¬íšŒì ê²½ì œ"

                try:
                    poster_img = driver.find_element(By.CSS_SELECTOR, "div.poster img")
                    description = poster_img.get_attribute("src")
                except:
                    description = "ìƒì„¸ ë§í¬ ì°¸ê³ "

                results.append({
                    "ê³µê³  ì œëª©": title_detail,
                    "ì£¼ê´€ê¸°ê´€": agency,
                    "ì‹ ì²­ ì‹œì‘ì¼": start_date,
                    "ì‹ ì²­ ì¢…ë£Œì¼": end_date,
                    "ê³µê³  ìœ í˜•": announcement_type,
                    "ì¹´í…Œê³ ë¦¬": category,
                    "ìƒì„¸ ë‚´ìš©": description,
                    "ì—°ê²° ë§í¬": detail_link
                })

                print(f"ğŸ“„ [{idx+1}] {title_detail} ìˆ˜ì§‘ ì™„ë£Œ!")

                driver.close()
                driver.switch_to.window(driver.window_handles[0])
                time.sleep(1)

            except Exception as e:
                print(f"âš ï¸ [{idx+1}] ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                if len(driver.window_handles) > 1:
                    driver.close()
                    driver.switch_to.window(driver.window_handles[0])
                continue

    except Exception as e:
        print(f"âŒ ì „ì²´ ì‹¤íŒ¨: {e}")

    finally:
        driver.quit()

    # âœ… ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("\nğŸ“„ ìµœì¢… ìˆ˜ì§‘ ê²°ê³¼:")
    for res in results:
        print(res)

    return results

if __name__ == "__main__":
    run_sehub_crawling()
