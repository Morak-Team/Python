# ğŸ“Œ ë„¤ì´ë²„íŒŒì´ë‚¸ì…œ ë§ˆì´ë¹„ì¦ˆ í¬ë¡¤ëŸ¬
# GPTë¡œ ìƒì„¸ë‚´ìš© ë‹¤ë“¬ê¸° í•„ìš”

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time

def run_mybiz_crawling():
    driver = webdriver.Chrome()
    driver.get("https://mybiz.pay.naver.com/subvention/search")
    wait = WebDriverWait(driver, 10)
    results = []

    try:
        # í•„í„° í´ë¦­: ì§€ì—­
        region_filter = wait.until(EC.element_to_be_clickable((By.XPATH, "//button[contains(., 'ì§€ì—­')]")))
        region_filter.click()
        print("âœ… ì§€ì—­ í•„í„° ì—´ê¸° ì™„ë£Œ")

        seoul_button = wait.until(EC.element_to_be_clickable((By.XPATH, "//button[contains(., 'ì„œìš¸íŠ¹ë³„ì‹œ')]")))
        seoul_button.click()
        print("âœ… ì„œìš¸íŠ¹ë³„ì‹œ ì„ íƒ ì™„ë£Œ")

        time.sleep(1)

        # í•„í„° í´ë¦­: ìš°ëŒ€ì‚¬í•­
        preference_filter = wait.until(EC.element_to_be_clickable((By.XPATH, "//button[contains(., 'ìš°ëŒ€ì‚¬í•­')]")))
        preference_filter.click()
        print("âœ… ìš°ëŒ€ì‚¬í•­ í•„í„° ì—´ê¸° ì™„ë£Œ")

        time.sleep(1)

        # ì‚¬íšŒì ê¸°ì—…(ì¸ì¦) í´ë¦­
        try:
            social_enterprise_div = driver.find_element(By.XPATH, "//div[contains(text(), 'ì‚¬íšŒì ê¸°ì—…(ì¸ì¦)')]")
            driver.execute_script("arguments[0].click();", social_enterprise_div)
            print("âœ… ì‚¬íšŒì ê¸°ì—…(ì¸ì¦) ì„ íƒ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ì‚¬íšŒì ê¸°ì—…(ì¸ì¦) í´ë¦­ ì‹¤íŒ¨: {e}")
            driver.quit()
            return

        time.sleep(2)

        # ìŠ¤í¬ë¡¤ í•´ì„œ ê³µê³  ë‹¤ ê°€ì ¸ì˜¤ê¸°
        prev_count = 0
        for scroll_try in range(5):
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)
            items = driver.find_elements(By.CSS_SELECTOR, "li.guide_list_item")
            if len(items) == prev_count:
                break
            prev_count = len(items)
            print(f"â¬‡ï¸ ìŠ¤í¬ë¡¤ {scroll_try+1}íšŒ ì™„ë£Œ (í˜„ì¬ {len(items)}ê°œ)")

        items = driver.find_elements(By.CSS_SELECTOR, "li.guide_list_item")
        print(f"\nğŸš¨ ì´ {len(items)}ê±´ ê³µê³  ë°œê²¬\n")

        # ìµœëŒ€ 10ê°œê¹Œì§€ë§Œ
        for idx, item in enumerate(items[:10], 1):
            try:
                link_element = item.find_element(By.CSS_SELECTOR, "a.guide_list_link")
                link = link_element.get_attribute("href")

                # ìƒˆíƒ­ ì—´ê³  ì´ë™
                driver.execute_script("window.open(arguments[0]);", link)
                driver.switch_to.window(driver.window_handles[1])

                time.sleep(2)

                # ë°ì´í„° ì¶”ì¶œ
                try:
                    title_detail = driver.find_element(By.CSS_SELECTOR, "p.detail_desc").text.strip()
                except:
                    title_detail = "ìƒì„¸ ë§í¬ ì°¸ê³ "

                try:
                    org_detail = driver.find_element(By.CSS_SELECTOR, "span.mss_txt").text.strip()
                except:
                    org_detail = "ìƒì„¸ ë§í¬ ì°¸ê³ "

                # ì‹ ì²­ ì‹œì‘ì¼/ì¢…ë£Œì¼ì€ ìƒì„¸ ë§í¬ ì°¸ê³ ë¡œ ê³ ì •
                start_date = "ìƒì„¸ ë§í¬ ì°¸ê³ "
                end_date = "ìƒì„¸ ë§í¬ ì°¸ê³ "

                try:
                    tag_element = driver.find_element(By.CSS_SELECTOR, "li[class*='theme_']")
                    tag_text = tag_element.text.strip()
                except:
                    tag_text = "ìƒì„¸ ë§í¬ ì°¸ê³ "

                try:
                    # ğŸ”¥ ì—¬ê¸° ìˆ˜ì •: 3ë²ˆì§¸ guide_view_content_v2 ì•ˆ p íƒœê·¸
                    guide_sections = driver.find_elements(By.CSS_SELECTOR, "div.guide_view_content_v2")
                    if len(guide_sections) >= 3:
                        third_section = guide_sections[2]
                        p_tag = third_section.find_element(By.TAG_NAME, "p")
                        content_text = p_tag.text.strip()
                    else:
                        content_text = "ìƒì„¸ ë§í¬ ì°¸ê³ "
                except:
                    content_text = "ìƒì„¸ ë§í¬ ì°¸ê³ "

                results.append({
                    "ê³µê³  ì œëª©": title_detail,
                    "ì£¼ê´€ê¸°ê´€": org_detail,
                    "ì‹ ì²­ ì‹œì‘ì¼": start_date,
                    "ì‹ ì²­ ì¢…ë£Œì¼": end_date,
                    "ê³µê³  ìœ í˜•": tag_text,
                    "ìƒì„¸ ë‚´ìš©": content_text,
                    "ì—°ê²° ë§í¬": link
                })

                print(f"ğŸ“„ [{idx}] {title_detail} ìˆ˜ì§‘ ì™„ë£Œ!")

                driver.close()
                driver.switch_to.window(driver.window_handles[0])
                time.sleep(1)

            except Exception as e:
                print(f"âš ï¸ [{idx}] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                if len(driver.window_handles) > 1:
                    driver.close()
                    driver.switch_to.window(driver.window_handles[0])
                continue

    except Exception as e:
        print(f"âŒ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {e}")

    finally:
        driver.quit()

    print("\nğŸ“„ ìµœì¢… ìˆ˜ì§‘ ê²°ê³¼:")
    for res in results:
        print(res)

    return results

if __name__ == "__main__":
    run_mybiz_crawling()
