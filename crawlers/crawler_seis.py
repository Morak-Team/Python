# ğŸ“Œ ì‚¬íšŒì  ê¸°ì—… í¬í„¸ í¬ë¡¤ëŸ¬
# GPTë¡œ ìƒì„¸ë‚´ìš© ë‹¤ë“¬ê¸° í•„ìš”

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
import re

EXCLUDED_KEYS = {
    "ìˆ˜í–‰ê¸°ê´€ êµ¬ë¶„", "ë‹´ë‹¹ë¶€ì„œ", "ë‹´ë‹¹ì ë° ì—°ë½ì²˜", "ì§€ì›ì§€ì—­", "ì²¨ë¶€íŒŒì¼", ""
}

def parse_period(period_text):
    """ '2025-04-22 ~ 2025-05-09' í˜•íƒœë¥¼ start, endë¡œ ë‚˜ëˆ„ëŠ” í•¨ìˆ˜ """
    if not period_text:
        return "ë¯¸ì •", "ë¯¸ì •"
    match = re.match(r"(\d{4}-\d{2}-\d{2})\s*~\s*(\d{4}-\d{2}-\d{2})", period_text)
    if match:
        return match.group(1), match.group(2)
    else:
        return "ë¯¸ì •", "ë¯¸ì •"

def parse_detail_page(driver):
    result = {}
    details = driver.find_elements(By.CSS_SELECTOR, ".view_box_items li")
    for li in details:
        try:
            dt = li.find_element(By.CSS_SELECTOR, "dt").text.strip().replace(":", "")
            dd = li.find_element(By.CSS_SELECTOR, "dd").text.strip()
            if dt not in EXCLUDED_KEYS:
                result[dt] = dd
        except:
            continue

    # ì•ˆë‚´ì‚¬í•­ div ë”°ë¡œ ì¶”ì¶œ
    try:
        all_dt = driver.find_elements(By.CSS_SELECTOR, ".view_box_items dt")
        for dt in all_dt:
            if "ì•ˆë‚´ì‚¬í•­" in dt.text:
                dd = dt.find_element(By.XPATH, "following-sibling::dd[1]")
                guide_div = dd.find_element(By.CSS_SELECTOR, 'div[style*="white-space:pre-wrap"]')
                result["ì•ˆë‚´ì‚¬í•­"] = guide_div.text.strip()
                break
    except:
        result["ì•ˆë‚´ì‚¬í•­"] = ""

    return result

def run_seis_crawling():
    driver = webdriver.Chrome()
    driver.get("https://www.seis.or.kr/home/sub.do?menukey=7208")
    wait = WebDriverWait(driver, 10)

    # ì„œìš¸ í´ë¦­
    seoul_button = wait.until(EC.element_to_be_clickable((By.XPATH, '//button[text()="ì„œìš¸"]')))
    driver.execute_script("arguments[0].scrollIntoView(true);", seoul_button)
    seoul_button.click()
    time.sleep(1)

    # ì§„í–‰ì¤‘ í´ë¦­
    state_button = wait.until(EC.element_to_be_clickable((By.XPATH, '//button[text()="ì§„í–‰ì¤‘"]')))
    driver.execute_script("arguments[0].scrollIntoView(true);", state_button)
    state_button.click()
    time.sleep(1)

    # ê²€ìƒ‰ í´ë¦­
    search_button = wait.until(EC.element_to_be_clickable((By.XPATH, '//button[contains(@class, "btn_primary") and contains(text(), "ê²€ìƒ‰")]')))
    driver.execute_script("arguments[0].scrollIntoView(true);", search_button)
    search_button.click()
    time.sleep(1)

    results = []
    page = 1

    while True:
        wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'ul.board_data_box li li.subj')))
        title_elements = driver.find_elements(By.CSS_SELECTOR, 'ul.board_data_box li li.subj')

        for idx in range(len(title_elements)):
            title_elements = driver.find_elements(By.CSS_SELECTOR, 'ul.board_data_box li li.subj')
            title_text = title_elements[idx].text.strip()

            print(f"[{len(results)+1}] {title_text} â†’ ìƒì„¸ ì§„ì… ì¤‘...")
            driver.execute_script("arguments[0].scrollIntoView(true);", title_elements[idx])
            title_elements[idx].click()

            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, ".view_box_items")))
            time.sleep(0.5)

            parsed = parse_detail_page(driver)

            # í˜„ì¬ URL ë”°ì˜¤ê¸°
            current_url = driver.current_url

            # ì‹ ì²­ ê¸°ê°„ ë¶„ë¦¬
            period_raw = parsed.get("ê²Œì‹œê¸°ê°„", parsed.get("ê³µê³ ê¸°ê°„", parsed.get("ì ‘ìˆ˜ê¸°ê°„", "")))
            start_date, end_date = parse_period(period_raw)

            # ê²°ê³¼ ì €ì¥
            result = {
                "ê³µê³  ì œëª©": title_text,
                "ì£¼ê´€ê¸°ê´€": parsed.get("ìˆ˜í–‰ê¸°ê´€", "ë¯¸ì •"),
                "ì‹ ì²­ ì‹œì‘ì¼": start_date,
                "ì‹ ì²­ ì¢…ë£Œì¼": end_date,
                "ì¹´í…Œê³ ë¦¬": "ì‚¬íšŒì ê²½ì œ",
                "ìƒì„¸ ë‚´ìš©": parsed.get("ì•ˆë‚´ì‚¬í•­", "ì•ˆë‚´ì‚¬í•­ ì—†ìŒ"),
                "ì—°ê²° ë§í¬": current_url,
            }

            results.append(result)

            driver.back()
            wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'ul.board_data_box li li.subj')))

        try:
            next_btn = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'a.bt_next')))
            driver.execute_script("arguments[0].scrollIntoView(true);", next_btn)
            next_btn.click()
            page += 1
            time.sleep(1)
        except:
            print("ğŸ“„ ëª¨ë“  í˜ì´ì§€ ì™„ë£Œ")
            break

    driver.quit()
    return results

if __name__ == "__main__":
    results = run_seis_crawling()
    for r in results:
        print(r)
