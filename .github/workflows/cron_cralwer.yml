name: Daily Crawling at 6AM KST

on:
  schedule:
    - cron: "0 21 * * *" # 한국시간 오전 6시 = UTC 21시
  workflow_dispatch:

jobs:
  crawl:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Generate .env file from GitHub Secrets
        run: |
          echo "MYSQL_HOST=${{ secrets.MYSQL_HOST }}" >> .env
          echo "MYSQL_USER=${{ secrets.MYSQL_USER }}" >> .env
          echo "MYSQL_PASSWORD=${{ secrets.MYSQL_PASSWORD }}" >> .env
          echo "MYSQL_DATABASE=${{ secrets.MYSQL_DATABASE }}" >> .env
          echo "DISCORD_WEBHOOK_URL=${{ secrets.DISCORD_WEBHOOK_URL }}" >> .env
          echo "OPEN_API_KEY=${{ secrets.OPEN_API_KEY }}" >> .env
          echo "BIZ_INFO_API_KEY=${{ secrets.BIZ_INFO_API_KEY }}" >> .env

      - name: Export OPENAI_API_KEY as environment variable
        run: echo "OPENAI_API_KEY=${{ secrets.OPEN_API_KEY }}" >> $GITHUB_ENV

      - name: Run Crawling Script
        run: |
          python main.py
