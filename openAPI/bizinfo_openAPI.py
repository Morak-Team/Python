# ğŸ‘¾ ê¸°ì—…ë§ˆë‹¹ ê³µê³µ API 
# GPTë¡œ ìƒì„¸ë‚´ìš© ë‹¤ë“¬ê¸° í•„ìš”

from dotenv import load_dotenv
import os
import requests
import re

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

API_URL = "https://www.bizinfo.go.kr/uss/rss/bizinfoApi.do"
API_KEY = os.getenv("BIZ_INFO_API_KEY")

params = {
    "crtfcKey": API_KEY,
    "dataType": "json",
    "hashtags": "ì„œìš¸",  # ì„œìš¸ í‚¤ì›Œë“œ
}

def parse_period(period_text):
    """20220727 ~ 20220930 í˜•íƒœë¥¼ 2022-07-27, 2022-09-30ìœ¼ë¡œ ë³€í™˜"""
    if not period_text:
        return "ìƒì„¸ ë§í¬ ì°¸ê³ ", "ìƒì„¸ ë§í¬ ì°¸ê³ "
    match = re.match(r"(\d{8})\s*~\s*(\d{8})", period_text)
    if match:
        start = match.group(1)
        end = match.group(2)
        return f"{start[:4]}-{start[4:6]}-{start[6:]}", f"{end[:4]}-{end[4:6]}-{end[6:]}"
    else:
        return "ìƒì„¸ ë§í¬ ì°¸ê³ ", "ìƒì„¸ ë§í¬ ì°¸ê³ "

def extract_first_p_text(html_text):
    """<p>...</p> ì¤‘ ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸ë§Œ ë½‘ëŠ”ë‹¤"""
    if not html_text:
        return "ìƒì„¸ ë§í¬ ì°¸ê³ "
    start_idx = html_text.find("<p>")
    end_idx = html_text.find("</p>", start_idx)
    if start_idx != -1 and end_idx != -1:
        return html_text[start_idx + 3:end_idx].strip()
    else:
        return "ìƒì„¸ ë§í¬ ì°¸ê³ "

def fetch_bizinfo_data(limit=20):
    """ê¸°ì—…ë§ˆë‹¹ APIë¡œë¶€í„° ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê³ , ìµœëŒ€ limitê°œê¹Œì§€ ë°˜í™˜"""
    res = requests.get(API_URL, params=params)
    res.raise_for_status()
    data = res.json()

    items = data.get("jsonArray", [])

    # ğŸ” 'ì„œìš¸' í¬í•¨ëœ ê³µê³ ë§Œ í•„í„°ë§
    seoul_items = [
        item for item in items
        if any([
            "ì„œìš¸" in (item.get("jrsdInsttNm") or ""),
            "ì„œìš¸" in (item.get("excInsttNm") or ""),
            "ì„œìš¸" in (item.get("bsnsSumryCn") or ""),
            "ì„œìš¸" in (item.get("hashTags") or ""),
        ])
    ]

    print(f"âœ… ì´ {len(seoul_items)}ê±´ì˜ 'ì„œìš¸' ê´€ë ¨ ì§€ì›ì‚¬ì—…ì´ ê²€ìƒ‰ë˜ì—ˆìŠµë‹ˆë‹¤.\n")

    # ğŸ“Œ ê°€ì ¸ì˜¨ í›„ ìµœëŒ€ limitê°œë§Œ ì¶”ì¶œ
    selected_items = seoul_items[:limit]

    results = []

    for item in selected_items:
        title = item.get("pblancNm", "ìƒì„¸ ë§í¬ ì°¸ê³ ")
        organization = item.get("jrsdInsttNm", "ìƒì„¸ ë§í¬ ì°¸ê³ ")
        period_text = item.get("reqstBeginEndDe") or item.get("reqstDt") or ""
        start_date, end_date = parse_period(period_text)
        announce_type = item.get("pldirSportRealmLclasCodeNm", "ìƒì„¸ ë§í¬ ì°¸ê³ ")
        link = "https://www.bizinfo.go.kr" + item.get("pblancUrl", "")

        raw_summary = item.get("bsnsSumryCn", "")
        summary = extract_first_p_text(raw_summary)

        result = {
            "ê³µê³  ì œëª©": title,
            "ì£¼ê´€ê¸°ê´€": organization,
            "ì‹ ì²­ ì‹œì‘ì¼": start_date,
            "ì‹ ì²­ ì¢…ë£Œì¼": end_date,
            "ê³µê³  ìœ í˜•": announce_type,
            "ìƒì„¸ ë‚´ìš©": summary,
            "ì—°ê²° ë§í¬": link,
        }
        results.append(result)

    return results

if __name__ == "__main__":
    results = fetch_bizinfo_data(limit=20)  # ğŸ”¥ 20ê°œ ì œí•œ ì ìš©
    for r in results:
        print(r)
